{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b41dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#import numpy as np \n",
    "#import * #bring all module all at once \n",
    "#from collections import Counter  \n",
    "\n",
    "# Import all other necessary libraries. Your code below ...\n",
    "#import re\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3997d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n",
      "Training Model using Gaussian Naibe Bayes algorithm .....\n",
      "Training completed\n",
      "testing trained model to predict Test Data labels\n",
      "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels: \n",
      "0.9653846153846154\n",
      "\n",
      "\n",
      "=============== End of the program ===============\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function to create a dictionary of the most common words in emails\n",
    "def make_Dictionary(root_dir):\n",
    "    all_words = []\n",
    "    # Get a list of file paths for all emails in the directory\n",
    "    emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
    "    for mail in emails:\n",
    "        with open(mail) as m:\n",
    "            for line in m:\n",
    "                words = line.split()\n",
    "                all_words += words\n",
    "    # Use Counter to count word frequencies in all emails\n",
    "    dictionary = Counter(all_words)\n",
    "    \n",
    "    # Remove non-alphabetic tokens and single character tokens from the dictionary\n",
    "    list_to_remove = list(dictionary.keys())\n",
    "    for item in list_to_remove:\n",
    "        if not item.isalpha():\n",
    "            del dictionary[item]\n",
    "        elif len(item) == 1:\n",
    "            del dictionary[item]\n",
    "            \n",
    "    # Select the top 3000 most common words to use in the dictionary\n",
    "    dictionary = dictionary.most_common(3000)\n",
    "    return dictionary\n",
    "\n",
    "# Function to extract features from emails based on the dictionary\n",
    "def extract_features(mail_dir):\n",
    "    files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
    "    # Initialize the matrix to hold feature vectors and the array for labels\n",
    "    features_matrix = np.zeros((len(files),3000))\n",
    "    train_labels = np.zeros(len(files))\n",
    "    docID = 0\n",
    "    for fil in files:\n",
    "        with open(fil) as fi:\n",
    "            for i,line in enumerate(fi):\n",
    "                # Only process the third line of each email (where content often starts)\n",
    "                if i == 2:\n",
    "                    words = line.split()\n",
    "                    for word in words:\n",
    "                        for i,d in enumerate(dictionary):\n",
    "                            if d[0] == word:\n",
    "                                # Increment the word count for this document in the feature matrix\n",
    "                                features_matrix[docID,i] = words.count(word)\n",
    "        # Set the label for this document (0 for normal, 1 for spam)\n",
    "        train_labels[docID] = 0\n",
    "        filepathTokens = fil.split('/')\n",
    "        lastToken = filepathTokens[-1]\n",
    "        if lastToken.startswith(\"spmsg\"):\n",
    "            train_labels[docID] = 1\n",
    "        docID += 1\n",
    "    return features_matrix, train_labels\n",
    "\n",
    "# Directories containing the training and test email datasets\n",
    "TRAIN_DIR = \"./train-mails\"\n",
    "TEST_DIR = \"./test-mails\"\n",
    "\n",
    "# Build the dictionary from the training dataset\n",
    "dictionary = make_Dictionary(TRAIN_DIR)\n",
    "\n",
    "print(f'reading and processing emails from TRAIN and TEST folders')\n",
    "# Extract features and labels from the training and test datasets\n",
    "features_matrix, labels = extract_features(TRAIN_DIR)\n",
    "test_feature_matrix, test_labels = extract_features(TEST_DIR)\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes model\n",
    "model = GaussianNB()\n",
    "\n",
    "print(f'Training Model using Gaussian Naibe Bayes algorithm .....')\n",
    "# Train the model using the training dataset\n",
    "model.fit(features_matrix, labels)\n",
    "print(f'Training completed')\n",
    "# Predict the labels of the test dataset\n",
    "predicted_labels = model.predict(test_feature_matrix)\n",
    "print(f'testing trained model to predict Test Data labels')\n",
    "\n",
    "# Print the accuracy of the model on the test dataset\n",
    "print(f'Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels: \\n{accuracy_score(test_labels, predicted_labels)}')\n",
    "#print end of the program\n",
    "print(f'\\n\\n{\"=\"*15} End of the program {\"=\"*15}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877b1c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ab55cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c25443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888eeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66bb91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63588588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758566c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217dced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
